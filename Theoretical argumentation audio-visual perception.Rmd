---
title: "Theoretical argumentation / audio-visual perception"
author: "Yo"
date: "2022-09-20"
output: github_document
---
#Motor Theory

Liberman et al, (1967) claims that objects of speech perception are articulatory rather than acoustic or auditory events, defining gestures as the fundamental representation.Gestures are defined as the movents that tongue, lips, vocal folds, etc produce in order to articulate an specific sound. 

The theory states that if the speaker is able to determine the gesture that was produced, then s/he will be able to determine the sound. In other words we map acoustic signals to the gestures that produce it. Perceived similarities will correspond more closely to the articulatory than the acustic similarities. 

The model suggests that there is a speech perception module that monitors incoming acustic stimulation. 

# Direct Realist Theory of Speech Perception. 

Similarly to the MT claims that the elements of speech perception are articulatory rather than acoustic events. For the DRT there is no perception module but rather it is a visual perception of surface layout. Thus following DRT talker's gestures such as moving lips structures the acoustic signal which is later recovered by the listener. The term direct in Direct Realism is meant to imply that perception of gestures and sounds is rich enough by itself and does not need a perceptual module. 

Interestingly temporal overlap of consonants and vowels do not merge or asimilate, but rather coarticulate. 



If there is no device that help us processing, humans may use all the information available to obtain meaning. 











